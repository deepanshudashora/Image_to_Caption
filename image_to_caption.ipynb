{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "\n",
    "from prepare_images import extract_image_features\n",
    "from prepare_text import clean_text_data, preprocessed\n",
    "from image_model import return_model, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf. test. is_built_with_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = 'Data/training_Images/'\n",
    "train_images = glob(train_images_path+'*.jpg')\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Testing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = 'Data/testing_images/'\n",
    "test_images = glob(test_images_path+'*.jpg')\n",
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 10\n",
    "h = 10\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "columns = 5\n",
    "rows = 1\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = cv2.imread(train_images[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incept_model = ResNet50(include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the last 2 layers\n",
    "last_layers = incept_model.layers[-2].output\n",
    "# Setting up the model input and output\n",
    "model = Model(inputs = incept_model.input,outputs = last_layers)\n",
    "\n",
    "\n",
    "with open('resnet_model_summary.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_features = extract_image_features(train_images,model)\n",
    "test_images_features = extract_image_features(test_images,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images_features))\n",
    "print(len(test_images_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_caption_path = 'Data/training_captions.txt'\n",
    "train_captions = open(train_caption_path, 'rb').read().decode('utf-8').split('\\n')\n",
    "train_captions, train_error_count = clean_text_data(train_captions, train_images_features)\n",
    "print(len(train_captions))\n",
    "print(\"Error in : \", train_error_count)\n",
    "\n",
    "test_caption_path = 'Data/testing_caption.txt'\n",
    "test_captions = open(test_caption_path, 'rb').read().decode('utf-8').split('\\n')\n",
    "test_captions, test_error_count = clean_text_data(test_captions, test_images_features)\n",
    "print(len(test_captions))\n",
    "print(\"Error in : \", test_error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in train_captions.items():\n",
    "    for vv in v:\n",
    "        train_captions[k][v.index(vv)] = preprocessed(vv)\n",
    "        \n",
    "for k,v in test_captions.items():\n",
    "    for vv in v:\n",
    "        test_captions[k][v.index(vv)] = preprocessed(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = {}\n",
    "for k,vv in train_captions.items():\n",
    "    for v in vv:\n",
    "        for word in v.split():\n",
    "            if word not in count_words:\n",
    "\n",
    "                count_words[word] = 0\n",
    "\n",
    "            else:\n",
    "                count_words[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = -1\n",
    "count = 1\n",
    "new_dict = {}\n",
    "for k,v in count_words.items():\n",
    "    if count_words[k] > THRESH:\n",
    "        new_dict[k] = count\n",
    "        count += 1\n",
    "        \n",
    "print(len(new_dict))\n",
    "new_dict['<OUT>'] = len(new_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions_backup = train_captions.copy()\n",
    "train_captions_dict = train_captions_backup.copy()\n",
    "\n",
    "test_captions_backup = test_captions.copy()\n",
    "test_captions_dict = test_captions_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, vv in train_captions_dict.items():\n",
    "    for v in vv:\n",
    "        encoded = []\n",
    "        for word in v.split():  \n",
    "            if word not in new_dict:\n",
    "                encoded.append(new_dict['<OUT>'])\n",
    "            else:\n",
    "                encoded.append(new_dict[word])\n",
    "        train_captions_dict[k][vv.index(v)] = encoded\n",
    "print(len(train_captions_dict))\n",
    "\n",
    "        \n",
    "for k, vv in test_captions_dict.items():\n",
    "    for v in vv:\n",
    "        encoded = []\n",
    "        for word in v.split():  \n",
    "            if word not in new_dict:\n",
    "                encoded.append(new_dict['<OUT>'])\n",
    "            else:\n",
    "                encoded.append(new_dict[word])\n",
    "        test_captions_dict[k][vv.index(v)] = encoded    \n",
    "print(len(test_captions_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MAX_LEN = 0\n",
    "for k, vv in train_captions_dict.items():\n",
    "    for v in vv:\n",
    "        if len(v) > train_MAX_LEN:\n",
    "            train_MAX_LEN = len(v)\n",
    "            print(v)\n",
    "\n",
    "test_MAX_LEN = 0\n",
    "for k, vv in test_captions_dict.items():\n",
    "    for v in vv:\n",
    "        if len(v) > test_MAX_LEN:\n",
    "            test_MAX_LEN = len(v)\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "def generator(photo, caption, MAX_LEN, VOCAB_SIZE):\n",
    "    n_samples = 0\n",
    "    X = []\n",
    "    y_in = []\n",
    "    y_out = []\n",
    "    for k, vv in caption.items():\n",
    "        for v in vv:\n",
    "            for i in range(1, len(v)):\n",
    "                X.append(photo[k])\n",
    "                in_seq= [v[:i]]\n",
    "                out_seq = v[i]\n",
    "                in_seq = pad_sequences(in_seq, maxlen=MAX_LEN, padding='post', truncating='post')[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=VOCAB_SIZE)[0]\n",
    "                y_in.append(in_seq)\n",
    "                y_out.append(out_seq)\n",
    "    return np.array(X), np.array(y_in, dtype=\"float64\"), np.array(y_out, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 32\n",
    "VOCAB_SIZE = len(new_dict)\n",
    "\n",
    "X_train, y_in_train, y_out_train = generator(train_images_features, train_captions_dict, train_MAX_LEN, VOCAB_SIZE)\n",
    "X_test, y_in_test, y_out_test = generator(test_images_features, test_captions_dict, test_MAX_LEN, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "max_len = train_MAX_LEN\n",
    "vocab_size = len(new_dict)\n",
    "\n",
    "image_model = return_model(embedding_size, max_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.fit([X_train, y_in_train], y_out_train, validation_data=([X_test,y_in_test], y_out_test), batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0400c4516344e023e97520252fec1aae26c6949600806b05139a5f166c2303ec8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
